\documentclass[a4paper,10pt]{article}
\usepackage{amsmath}
\usepackage{amsthm}
\newtheorem{mydef}{Definition}
\usepackage{url, hyperref}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\usepackage{fullpage}
\usepackage{tikz}
\usepackage{float}
\usepackage{listings}
\usepackage{color}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\bibliographystyle{plain}

\title{Project Proposal Presentation: Efficient segmentation algorithms for
shark fin identification}
\author{L. Cilli\'{e}, 16010450}
\date{1 August 2013}

\begin{document}
\maketitle
\section{Motivation and problem statement}
Just as humans are identified by their fingerprints, sharks have an unique
dorsal fin structure.  Because of environmental issues, estimating the
population of a specific shark specie, for example, has become a hot topic under
marine scientists.  The idea behind the project originated when PhD
student in Marine Biology, Ms. Sara Andreotti, approached Dr. van der Walt for
help
regarding a problem she encountered in her research?. \\ 

The problem presented was
as follows.  The work Ms. Andreotti does involve going out into the ocean and
taking photographs of shark fins to later study their ecological and behavioural
patterns, for example.  Now all these photos get put into a databases. But to
make any reliable conclusions, like have we seen this shark before?  How many
times? Where? When?, there has to be some form of identification in the
databases. 
Naturally one would put all the images of a certain shark in one category.  We
already know that it is possible to categorize each image, because of the
uniqueness of the dorsal fin.  One would just have to find a way to match new
input data with existing images in the databases.  But imagine doing this
manually.  Since Ms. Andreotti does not want to focus her attention on
developing new software, but rather on the valuable conclusions she can make
thereafter, this is where we come in handy. \\

We will investigate different
methods for classifying the foreground and background of the image
and then segmenting the foreground, or certain parts of it, successfully for the
matching process.  By doing so, the burden on marine scientists can be readily 
reduced.


\section{Background -- Image segmentation}
Image segmentation is well known in the field of image processing.  The basic
principle of image segmentation is partitioning an image into multiple segments
for some or other reason, for example to locate an object or boundaries in the
image.  In other words each pixel is assigned a label and all the pixels with
the same label share a certain property and forms a segment.  \\

Well known
examples where image processing is applied is in medical imaging to locate
tumours, face and fingerprint recognition as well as in video surveillance.  To
name only a few.  Today there are a number of different techniques to do image
segmentation of which a few will be discussed later.


\section{Examples of shark fin images}
Note the unique dorsal part on the fin.  Also, although the photos are of good
quality, only including the fin, the foreground and background properties can
vary significantly as you can see here.


\section{Algorithms from the scikit-image Python library}
The first algorithms we investigated, were the Watershed and Random Walker
algorithms included in the scikit-image library.  We did not have much success
with them and decided to turn our attention to a much simpler, yet more powerful
algorithm.


\section{The region growing GrowCut segmentation algorithm}
The GrowCut algorithm is an interactive, multi-label segmentation
algorithm for N-dimensional images.  The algorithm is based on cellular
automata, i.e.,  the user labels a few pixels and the rest of the image is then
segmented automatically by a cellular automaton. \\

Anyone familiar with cellular automata will know that the most important part
is the evolution rule, by which the state of the cell, in our case foreground or
background, is updated.  \\

In other words, after specifying a neighbourhood around the cells, in our case pixels, each iteration consists of
the neighbouring cells 'attacking' the cell under consideration.  The state of this cell is then updated
according to the evolution rule. This procedure then iterates throughout the image until each pixel has a label, either foreground or background.

So this approach really was very successful.\\

What we are currently busy with, in collaboration with one of the Masters
student, is we are building a pipeline for Ms. Andreotti
such that the input data is the shark fin image and the output is a specific
classification of that image,
also then telling us, for example, whether that shark has been seen before, where and when
it has been seen.
As mentioned before, the
algorithm requires the specification of a few foreground and background pixels. 
But since the orientation of the images are not all the same, we are immediately
faced with a problem. How to choose the coordinates universally?  Well, one
solution is to make sure the orientation of all the images are the same.
Other ideas are still in progress.


\section{DARWIN -- Alternative software}
Recently there appeared an article in Die Burger claiming
that this software could also be used for the identification and matching of
shark fin images to estimate the Great White shark population in the Gansbaai
area.  Well, this claim was tested by Ms. Andreotti and she found that in only
54\% of the cases the correct matching took place.  Making this software highly
unreliable. This then motivated us further to produce a reliable piece of
software for this purpose.


\section{Conclusions}
Future work include playing with the damping function in the GrowCut algorithm and considering other
attacking strategies.
One of the most satisfying aspects of this project for me is the practical
application of the topic in the real world.  Not only that, but also the
privilege we have to actually present our software to Ms. Andreotti, in aid of
her PhD.   \\

Thank you very much for listening.

\end{document}