\documentclass[a4paper,10pt]{article}
\usepackage{amsmath}
\usepackage{amsthm}
\newtheorem{mydef}{Definition}
\usepackage{url, hyperref}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
%\usepackage{fullpage}
\usepackage{tikz}
\usepackage{float}
\usepackage{listings}
\usepackage{color}
\usepackage{mathtools}
\usepackage[T1]{fontenc}
\usepackage{subfigure}
\usepackage{algorithm}
\usepackage{algpseudocode}
\bibliographystyle{plain}

\newenvironment{changemargin}[2]{%
\begin{list}{}{%
\setlength{\topsep}{0pt}%
\setlength{\leftmargin}{#1}%
\setlength{\rightmargin}{#2}%
\setlength{\listparindent}{\parindent}%
\setlength{\itemindent}{\parindent}%
\setlength{\parsep}{\parskip}%
}%
\item[]}{\end{list}}

\usepackage[linecolor=green!70!white,
backgroundcolor=blue!20!white,bordercolor=red]{todonotes}
\newcommand{\note}{\todo}

\begin{document}
\begin{titlepage}

\begin{changemargin}{-1cm}{-1cm}
\begin{center}

\begin{minipage}{1.2\textwidth}
\begin{center}
\vspace{2cm}
    {\Huge \bf Efficient segmentation algorithms for shark fin
identification }
\end{center}
\end{minipage}

\vspace{1.3cm}

\begin{minipage}{0.49\textwidth}
\begin{center} \LARGE
\emph{Author:}\\
L. Cilli\'{e}, 16010450
\end{center}
\end{minipage}
\begin{minipage}{0.49\textwidth}
\begin{center} \LARGE
\emph{Project Advisors:} \\
Prof. B.M. Herbst\\Dr. S.J Van der Walt

\end{center}
\end{minipage}

\vspace{1.3cm}
{\LARGE October 2013}

\end{center}

\vfill

\vspace{20mm}
\hfill{\LARGE Honours Project, Applied Mathematics}\hfill\,

\,\hfill{\LARGE Stellenbosch University}\hfill\,

\end{changemargin}

\end{titlepage}

\begin{abstract}
 
\end{abstract}

\newpage
\tableofcontents

\newpage
\section{Problem statement and motivation}
\subsection{}
Just as humans are identified by their fingerprints, sharks have a unique
dorsal fin structure.  Identifying shark sightings is very
valuable.  In order to do that and also to compare various shark sightings,
photos of
shark fins, as will be shown later, will be analysed by a computer. 
This consists of identifying the edges in the image and segmenting the
foreground, the shark fin being most prominent,  from the background, the sea. 
Although the photos provided are of a good quality and have been cropped
to only include the fin, the
foreground and background properties can still vary significantly, making this a
non-trivial problem.  This project aims to investigate efficient segmentation
algorithms for shark fin identification.  The approach consists of
evaluating (by means of a computer) different methods for classifying foreground
and background, as well as segmenting the foreground successfully.  By doing so,
the burden on biological researchers of transforming the images so that useful
information can be extracted from it, can be reduced.  \\

\note{Write a bit more formally: the project is motivated by...}The idea behind
the project originated when PhD
student in Marine Biology, Ms. Sara Andreotti, approached Dr. van der Walt for
help regarding a problem she encountered in her research.\note{Probably too
    personal in general.  We don't need to tell the story of the people
involved to motivate the scientific work.}
The problem presented was
as follows.  The work Ms. Andreotti does involve going out into the ocean,
taking photographs of shark fins and identifying those sharks to later study
their ecological and behavioural
patterns, for example.
All these photos are put into a databases. But to
make any reliable conclusions, such as: Have we seen this shark before?  How
many
times? Where? When?, there has to be some form of identification in the
databases.\note{Rewrite this section--tone too informal.} 
The goal is to group photos of a certain individual together.  We
already know that it is possible to categorize each image, because of the
uniqueness of the dorsal fin.  One would just have to find a way to match new
input data with existing images in the databases.  One can only imagine the
difficulty in doing this manually. 
Since Ms. Andreotti's
focus is on the distribution and movements of sharks and not on developing new
software, we can make a substantial contribution by researching this topic. 

Wil ook meer se oor die impak van so projek en ook oor die bewaring van die
haaie.

\newpage
Below are a few examples of the data used in this research project.  
The databases consists of various shark fin images, taken on different dates and
from different locations.
Also note that not every image corresponds to a unique shark, i.e. the databases
might contain two or more images of the same shark.

\begin{figure}[H]
\centering
\mbox{\subfigure[]{\includegraphics[width=2in]{haai1.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{haai4.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{haai2.jpg}}}
\end{figure}

\begin{figure}[H]
\centering
\mbox{\subfigure[]{\includegraphics[width=2in]{haai3.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{haai5.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{haai6.jpg}}}
\end{figure}

\begin{figure}[H]
\centering
\mbox{\subfigure[]{\includegraphics[width=2in]{haai7.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{haai8.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{haai9.jpg}}}
\end{figure}


\subsection{Background}
Image segmentation is commonly applied in image processing.  It
aims to partition a digital image into multiple segments for some or other
reason.
The image can then instead be interpreted using a small number of
well defined components as opposed to a large array of unrelated pixels.  
In other words each pixel is assigned a label and all the pixels with the same
label share a certain
property.  Thus making the image easier to analyse. Image segmentation is
typically used to locate an object or boundaries in an image. \\

Segmentation algorithms can be classified as either supervised, meaning that
it requires user interaction, or supervised, meaning that it is totally
automatic.  Segmentation is a hard
problem\note{Citation or motivation required.  Why??}.  Computers must segment
an
image knowing only limited information about colour and space, for example.
Many images can be very ambiguous \note{Dont know how to say this.}  and
supervised algorithms need user input to make decisions.  On the other hand,
unsupervised algorithms need predetermined information and assumptions to work
automatically.
It then follows that the unsupervised algorithms
do not perform as well as the supervised algorithms.  However, we strive to
develop accurate,
unsupervised algorithms. \\

Well known examples where image processing is used is
in medical imaging to locate tumours, for example, face and
fingerprint recognition and video surveillance.  See \ref{examples}.\note{What
is the purpose of this paragraph?  To give examples.}

\begin{figure}[H]
\centering
\mbox{\subfigure[]{\includegraphics[width=2in]{braintumor.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{face.jpg}}}
\caption{Image segmentation.}
\label{examples}
\end{figure}


Another challenge with image segmentation is the evaluation of the resulting
segmentations.  Often we don't have well defined criteria to evaluate the
segmentation. 
To make progress in this field it would be helpful to have a way for comparing
different
segmentation methods so that we know if progress is being made. 
The Berkeley Segmentation Dataset and Benchmark contains 12 000 hand-labelled
segmentations of 1 000 Corel dataset images from 30 human subjects. 
This can then be used to compare what humans think a good segmentation
should look like. \\

Here is an example of a colour image in the Berkeley Segmentation Dataset.  Note
that the image in the middle shows the machine segmentation and the
image on the right the human segmentation.

\begin{figure}[H]
\centering
\mbox{\subfigure[]{\includegraphics[width=2in]{data.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{data1.jpg}} \quad
\subfigure[]{\includegraphics[width=2in]{data2.jpg}}}
\end{figure}

For the purpose of this research project, such dataset will not be used for
comparison of results.  \note{Want to know how we are going to determine whether
the segmentation was successful?}

\subsection{Software -- Python}
For the purposes of this research project, the Python Programming Language was
used.  Reasons for this are because of its simplicity, the powerful set of tools
available in Python, the fact that it is easy to learn and also easy for other 
people to understand.  Python is
also free to use and runs on multiple platforms.  For the numerical and
scientific computations, Numpy and SciPy was used.
To improve the running time of the algorithms, Cython was used.  It is a
language that compiles to a Python extension module a super set of the
Python language that allows calling C-functions and declaring C-types on
variables and class attributes.  This
results in generating very efficient C-code from Cython code.
Scikit-image was used for the investigation of various image processing
techniques. \\

To ease collaboration, GitHub was used.  Github is a web-based hosting service
for open source software development projects.  This allowed us to easily
share 
code and documents and also quickly receive feedback.


\begin{figure}[H]
 \centering
 \includegraphics[width=3in]{logos.jpg}
\end{figure}

\newpage
\section{Overview of pipeline}
\note{Sal jy my asb kan help met n
diagram?}

\note{Write a concise overview of the pipeline here, then proceed to discuss
each component in detail.  Merge algorithm descriptions further down with this
section.}

\subsection{Orientation}
\label{orient}
To ease further analysis, we determine the
orientation of the shark fin in the image as the direction in
which the shark is
swimming, as viewed from the front, i.e. if the shark is swimming to the left,
the algorithm returns right and vice versa. This will then help to identify a
few foreground- and background
pixels needed in the segmentation process\note{expand and explain}
The method of Principal Components Analysis (PCA) is used here.  When applying
PCA, we are interested in finding the direction of maximum variation in the
data.  Suppose we have $K$, $n$-dimensional, data points, $\mathbf{x}_k,$ for
$k=1,2, \ldots ,K$. We compute a covariance matrix, $C$,
\[
 C_{\mathbf{x}} = \frac{1}{K} \sum_{k=1}^{K} \mathbf{x}_{k}\mathbf{x}_{k}^{T} -
\mathbf{m}_{\mathbf{x}}\mathbf{m}_{\mathbf{x}}^{T} 
,\]
where
\[
 \mathbf{m}_{\mathbf{x}} = \frac{1}{K} \sum_{k=1}^{K}\mathbf{x}_{k}
\]
is the mean of the data.  \\

\note{there is no indication what data we are talking about here--you have to
make sure the reader understands your story!}

From $C$ we determine the eigenvalues and eigenvectors, which will indicate the
variance and principal directions respectively.
The direction of the eigenvector corresponding to the largest eigenvalue will
then indicate the orientation of the shark fin. \\

\note{e.g., it is impossible to know what C is in relation to our coordinates
from the above description}

Below is a dummy shark fin image where the orientation is detected using PCA.
Note the principal axis, largest eigenvector, in blue, which gives the
orientation of the shark fin.
\begin{figure}[H]
 \centering
 \includegraphics[width=3in]{orientation.jpg}
 \caption{Orientation of the shark fin detected by means of PCA.}
 \label{orientation}
\end{figure}

When implementing the above method,\note{As compared to?  I always assume the
author implemented his/her method.}we start by converting the shark fin
image, which is an RGB image, to a grayscale image.  To ease the
process\note{To ease what process?}, we
apply a sobel filter to the image, justifying the reason for the colour
conversion\note{I don't understand}.  After identifying the prominent edges in
the image, we apply a threshold resulting in a image where every pixel value
greater than the geometric mean of the edge image times four is set to
zero.\note{Why is 4 times chosen?  I would also like to know???}
We can now do PCA on
the image to determine the principal axes of the coordinates.  If the gradient
of the line defining the principal direction lies between 0 and
$\frac{\pi}{2}$ radians, the orientation of the shark fin is
identified as
"right", otherwise \note{scratch up to end of "as".  What do you mean by
this?}the orientation is identified as "left". 

\subsection{Segmentation}
The task is to separate the foreground, the shark fin, from the background,
the sea.  For this purpose, we use the region growing segmentation algorithm,
Growcut (see \ref{growcut}).  Growcut requires the user to specify a few
foreground and background pixels from which the growing can be
initiated.\note{No description of growcut as an automaton?}
Initially this was done by first determining the orientation of the fin (see
\ref{orient}) and then specifying a few pixels according to that, see 
\ref{segmentation}.  \\

\begin{figure}[H]
 \centering
 \includegraphics[width=5in]{segmentation.jpg}
 \caption{Growcut segmentation on a shark fin image by selecting a few
foreground and background pixels, shown in blue and red respectively.}
 \label{segmentation}
\end{figure}

However, more success was achieved by rather reflecting the fin in the
horizontal direction to ensure that all the shark fins have the same
orientation.\note{It's not a matter of more success--it would be wrong to do
it any other way!}  The specification of
the foreground and background pixels is then done using the function
\texttt{grid\_points\_inside\_poly()} from the \texttt{morphology} module in
\texttt{scikit-image}.  This function selects all points inside a given
polygon.  These points are then set as the foreground and background pixels
respectively.\note{Sentence does not make sense}  See
\ref{segmentation1}.
Since the images in the databases, and images in general, are not
all the same size, we specify the corners of the polygon according to the size
of the image.\note{Show the triangles you define.  In the process of doing
that.}
This then makes the algorithm more robust.  \\

\begin{figure}[H]
 \centering
 \includegraphics[width=5in]{segmentation.jpg}
 \caption{Growcut segmentation on a shark fin image by selecting all points in a
given polygon as foreground and background pixels, shown as blue and red
 polygons respectively.}
 \label{segmentation1}
\end{figure}

Now that we have specified a few foreground and background pixels, we also
need to specify the size of the neighbourhood around cells when the algorithm
is 'growing' as well as the number of iterations the algorithm should follow.
These parameters inevitably influence the success of the
segmentation.\note{The reader cannot follow this explanation without knowing
how growcut works}
\\

Below is an example of the final output of the segmentation process. \\
\note{show at different stages, perhaps? Agree!}

\begin{figure}[H]
 \centering
 \includegraphics[width=5in]{segmentation.jpg}
 \caption{Growcut segmentation on a shark fin image by selecting all points in a
given polygon as foreground and background pixels, shown as blue and red
 polygons respectively.}
 \label{segmentation1}
\end{figure}


\subsection{Fin detection}
The objective is to identify the serrated part of dorsal shark fin. In order to
do this we need to extract the latter part of the fin such that it can be
compared with other fins\note{broken sentence.  What do you mean??}.  We use the
Sobel operator,
well-known in edge detection, to identify the edge and ease further analysis.
\note{What does "ease further analysis" mean here?}
The sobel operator is a discrete differential operator that approximates the
gradient of the image intensity function.  It uses two different $3 \times 3$
masks, $M_x$ and $M_y$, which are convolved with the original image to
approximate the
derivatives, both in the horizontal $x$-
and the vertical $y$-directions.  \\

Define $A$ as the input image and $G_x$ and $G_y$ as the gradient images in the
$x$-and $y$-direction respectively,
after convolving with $A$.  $M_x$ and $M_y$ is given by

\[
 M_x = \begin{pmatrix*}
        1 & 0 & -1 \\
        2 & 0 & -2 \\
        1 & 0 & -1
       \end{pmatrix*}
\mbox{ , }
 M_y = \begin{pmatrix*}
        1 & 2 & 1 \\
        0 & 0 & 0 \\
        -1 & -2 & -1
       \end{pmatrix*}
.\]

At each point in the image, the gradient approximations can be combined to give
the gradient magnitude image, calculated  as
\[
 G = \sqrt{G_x^2+G_y^2}
.\]

The sobel operator applied to one of the shark fin images is shown in
\ref{sobel}.  Note that this operator only works on a grayscale image.
We can see the edge of the fin in the $G$ image on the right clearly identified.

\begin{figure}[H]
 \centering
 \includegraphics[width=3in]{sobel.jpg}
 \caption{The Sobel operator.}
 \label{sobel}
\end{figure}

The next step is to extract only the unique part of the fin needed for
identification.  This is done by first inverting the edges and then squaring
them to increase their weight.\note{why?}  We make use of a function 
\texttt{route\_through\_array()} from the module \texttt{graph} in scikit-image.
 This function enables us to find a lowest cost path through the image.
Since we are working on the segmented image, we allow any start and end point
for the path.\note{How do we do that?}  The path is computed by ??????.  All
pixel coordinates running on the edges of the image is then removed from the
path. Hoe kan ons seker wees dat hy wel die fin gaan vind????\note{'n Mens kan
    seker nooit seker wees nie, maar as dit die mees prominente rant is sal hy
    dit vind.  Onthou om die eksperiment te doen waar jy die edge beeld
    inverteer en kyk of dit nogsteeds werk, sodat ons kan sien of hy klein
waardes of kontoere track.}\\

Here we show an example of the path, in blue, that was detected on the shark
fin.
\begin{figure}[H]
 \centering
 \includegraphics[width=5in]{finpath.jpg}
 \caption{Fin path detected.}
 \label{fin}
\end{figure}



\subsection{Dynamic Time Warping}
\note{For the pipeline overview, call the sections by their purpose: e.g.,
    here I would call the section "Fin matching", and then discuss how we use
DTW to achieve that.}Dynamic time warping (DTW) is an algorithm used for
measuring the similarity between two sequences which may vary in time or
speed.  It differs from normal comparison in the
sense that it accommodates sequences of different lengths, warping the
sequences for the best fit\note{best fit--what does that mean?}.
Any data that can be represented linearly can be analysed using DTW.  \\

When comparing two sequences, a typical approach is to calculate the distance
between corresponding points.  The Euclidean metric can be used
to calculate this distance, but
it assumes that the $i$-th \note{wys dat dit 'n inskrywing $A_ij$ vorm} point in
the first sequence will align with the $j$th point in the second sequence.
But
since the sequences need not be
the same length, we will make use of a non-linear alignment\note{explain}.

A distance matrix is calculated, contain the distance between
each pair of elements as entries.\note{vague}  We now view this matrix as a
grid, where the
aim is to find a lowest cost path from the top left corner to the bottom right
corner.\note{why?}
The minimum cost is then a measure of the similarity between the
sequences.\note{explain intuitively}
In other words, the lower the cost, the greater the match.
\\

For this part of the pipeline, the output from the fin detection method,
\note{diagram! Van wat???}i.e.
the coordinates of the path defining the shark fin, is used as input.  The DTW
method will follow the above procedure to compare every shark fin to every
other shark fin in the databases, each time returning a minimum cost.  
Thus for a databases containing $N$ shark fin images, a $N \times N$ cost
matrix will be returned, where the entry in $(i, j)$ corresponds to the cost
of the path when shark fin $i$ is compared to shark fin $j$. Hoe presies gaan
ons se dit is wel n match???? \note{Ons soek die minimum langs die
kolom van die koste-matriks}\\


Below is an example where two arrays are compared using DTW. Note the lines
connecting the points being compared.  \begin{figure}[H]
 \centering
 \includegraphics[width=3in]{dtw.jpg}
 \caption{Fins compared as arrays.}
 \label{dtw}
\end{figure}

\newpage
\subsection{DARWIN -- Alternative software}
The DARWIN\cite{Darwin} software package is well known when it comes to
aquiring important data about Great White Sharks.  It was initially implemented
by undergraduate student of
Eckerd College.
Lately it was used to estimate the Great White shark population in the
Gansbaai area by means of shark fin identification and matching.  They claim to
have found approximately
1008 different shark species in this region.  This
claim was tested by Ms. Andreotti and she found that in only
54\% of the cases the correct matching took place, making this software
unreliable.

\begin{figure}[H]
 \centering
 \includegraphics[width=3in]{Darwin.jpg}
 \caption{DARWIN user interface}
\end{figure}

\newpage
\section{Segmentation Algorithms}
\subsection{Different categories and techniques}
Segmentation algorithms can be arranged into different categories \cite{is}. 
Some of the most well-known categories are
\begin{itemize}
 \item \textbf{Thresholding}  Thresholding is an unsophisticated method. It
relies on
     selecting a good threshold
     value, using Otsu's method for example, to convert a gray-scale image into
a binary image.  Segmentation is
     then done on the binary image. 
 \item \textbf{Clustering} For these methods, the $K$-means algorithm
can be used to partition an image into $K$ clusters, whereafter
segmentation will follow.
 \item \textbf{Compression-based} This method conjectures that the
optimal segmentation is the one that minimizes, when considering all possible
segmentations, the coding length of the data. In other words, the number of bits
required to encode that image, based on the given segmentation.
 \item \textbf{Histogram-based}  This is a very efficient method in the
sense that it only passes through all the pixels once.  A histogram of 
the image is computed whereafter the peaks and valleys in the histogram
are used to locate clusters in the image.  Here clusters refer to pixels
sharing a certain property.  The colour or intensity of the pixels can be used to
locate clusters.
 \item \textbf{Edge detection} Edge detection is well researched in image
processing.  Region boundaries and edges are closely related,
since there are usually a sharp adjustment at region boundaries.  Edge detection
techniques can therefore be used as a bases for different segmentation
algorithms.
 \item \textbf{Region growing} This method takes as input not only
the image, but also a set of seeds, which marks the objects to be segmented. 
Thereafter neighbouring, unallocated pixels are compared to the specific seed
point.  That is how the region grows iteratively.  The pixels are compared using
the difference between intensity value and the region's mean.  Pixels are then
allocated to a specific region if that difference is a minimum.  The process
terminates if all pixels belong to a region.  \note{This is not accurate, I
don't think.  Region merging is all about merging *regions*.}
 \item \textbf{Watershed transformation} See description in \ref{watershed}.    
 \item \textbf{Graph partitioning} This method is based on modelling
the image as a weighted, undirected graph, where the nodes represent the pixels
and the weights represent the similarity between neighbouring pixels. Then the
graph is partitioned into clusters according to a specific criterion.  Each
partition is then considered an object segment in the image.
\note{References to all of these--above and below!  I do that at the top where I
introduce the section.}
 \item \textbf{Trainable} Also known as Neural network segmentation,
this process involves processing the small areas of an image by means of an
artificial neural network or a set of neural networks.  Thereafter, using the
categories recognised by the network, the decision-making mechanism marks the
image accordingly and segmentation is done.
\end{itemize}

\subsection{Cellular automaton}
\note{Why this all of a sudden?  you have to tie things together
logically...move to the growcut section}
A cellular automaton consists of a grid of cells, where each one of the cells
can be in a finite number of states.  In the case of segmenting an image,
    we typically use a two-state automaton, where the states indicate
foreground and background.  This must be specified
beforehand.  Around each cell, a set of cells, called the cell's neighbourhood,
exists.  An initial state, at time $t = 0$, is also assigned
to each cell.  A
new generation of cells is then created according to a fixed rule or
mathematical function that determines the new state of the cell, by looking at
the current state of the cell as well as that of its
neighbourhood.\note{vague}  This rule
is then applied to all of the cells simultaneously.  In this way, the cell's
state gets updated.  Note that the rules for each cell are the same and do not
change over time.\note{Can you implement an automaton from this description?
If not, update the description until you can answer "Yes"}

Two of the most common neighbourhood systems used are the Von
Neumann neighbourhood and the Moore neighbourhood which are shown below. 
Probably the most well-known example of a two dimensional automaton is Conway's
Game of Life.\note{Why not use game of life as an example to show how it
works?}  See \cite{gol} for further details.

\begin{figure}[H]
\centering
\mbox{\subfigure{\includegraphics[width=2in]{VonNeumann.png}} \quad
\subfigure{\includegraphics[width=2in]{Moore.png}}} \caption{Von Neumann and
Moore neighbourhood systems \cite{n}}
\end{figure}

\subsection{Growcut}
\label{growcut}
The Grow Cut algorithm is an interactive, multi-label segmentation algorithm
for N-dimensional images.  The algorithm is based on cellular automata, i.e.,
the user labels a few pixels and the rest of the image is then segmented
automatically by a cellular automaton\note{Sounds like magic...indicate to the
user that you are going to explain.  It's very uncomfortable to the reader
when it looks like he/she is already supposed to understand when, in fact, the
explanation is still on the way...}.  A cellular automaton consists of a
grid of cells, where each one of the cells can be in a finite number of
states, say on and off.   Around each cell, a set of cells, called the cell's
neighbourhood is defined.  An initial state, at time $t = 0$, is also assigned
to each cell.
A new generation of cells is then created according to a fixed rule or
mathematical function that determines the new state of the cell, by looking at
the current state of the cell as well
as that of its neighbourhood.\note{Exactly what you said above--give more
details on how these rules are formed for segmentation}  It is known that the
same rules apply to each cell and do not change over time.

The algorithm is interactive, since the user can observe the segmentation and
guide the algorithm in places where the segmentation is difficult to compute.
Some of the favourable properties of this algorithm is that it can do
segmentation on complex images and that it works with images of any
dimension.\note{Which segmentation algorithms don't?  And why wouldn't the
others work with complex images?}
\\


\noindent The basic method on which the algorithm relies is the following.  A
cellular automaton is an algorithm which is discrete in both space and time
and operates on a lattice of pixels $p \in P \subset Z^{n}$.  A cellular
automaton can be considered as a triplet, $A = (S, N, \delta)$, where $S$ is a
set containing different states, $N$ is the
neighbourhood system of the cell and $\delta: S^{N} \rightarrow S $ is a
transition rule.  This is the function which defines  the rule calculating the
cell's state at time $t + 1$, given the states 
of the cell's neighbourhood at time $t$.  Two well known neighbourhood systems
are the von Neumann and Moore neighbourhood systems.  The cell state referred to
is also
considered a triplet $(l_{p}, \theta_{p}, \overrightarrow{C}_{p})$, where
$l_{p}$ is the label of the cell($K$ labels in total), $\theta_{p}$ is the
'strength' of the cell and $\overrightarrow{C}_{p}$ is
the cell feature vector.  Without loss of generality it can be assumed that
$\theta_{p} \in [0,1]$. 
\note{This sounds like it was cut and pasted in.  Describe in your own words.}

The initial state of the pixels is set to $l_{p} = 0, \theta_{p} = 0,
\overrightarrow{C}_{p} = RGB_{p}$, where $RGB_{p}$ is a three dimensional vector
of the pixel's colour in 
the RGB space.  The goal of the segmentation is to assign one of the possible
$K$ labels to each one of the pixels.  The user starts the segmentation by
marking specific pixels as foreground and others as background.  This sets the
initial state of each pixel.  While the labels are being updated, the user can
correct and guide the process if desired.  \\

\newpage
\noindent The pseudo code for the automata evolution rule is shown below. 
\begin{algorithm}[H]
\begin{algorithmic}[1]
 \State // For each cell...
 \For{$\forall p \in P$}
 \State // Copy previous state
 \State $l^{t+1}_{p} = l^{t}_{p}$;
 \State $\theta_{p}^{t+1} = \theta_{p}^{t}$;
 \State // Neighbours try to attack the current cell
 \For{$\forall q \in N(p)$}
 \If{$g(\| \overrightarrow{C}_{p} - \overrightarrow{C}_{q} \|_{2}) \cdot
\theta^{t}_{q} > \theta_{p}^{t}$}
 \State $l^{t+1}_{p} = l^{t}_{q}$
 \State $\theta^{t+1}_{p} = g(\| \overrightarrow{C}_{p} - \overrightarrow{C}_{q}
\|_{2}) \cdot \theta^{t}_{q}$
 \EndIf
 \EndFor
 \EndFor
\end{algorithmic}
\end{algorithm}

\noindent where $g$ is a monotonous decreasing function bounded to $[0, 1]$. 
The function is given by
\[
g(x) = 1 - \frac{x}{max\| \overrightarrow{C} \|_{2}}. 
\]


\noindent The algorithm has been modified in the following way.  One of the
main features that needed attention was the damping function $g$.  By changing
the exponent of the term $\frac{x}{max\| \overrightarrow{C} \|_{2}}$ to
$\frac{3}{2}$, thus $\left ({\frac{x}{max\| \overrightarrow{C} \|_{2}}}\right
) ^\frac{3}{2}$,
an immediate result was seen.  The algorithm acted much more accurately around
the edges.  Next, the 'defend strength' of each pixel was modified also by
playing with exponents
of certain parts of the code.\note{yes, but why? explain what's happening!}  A
sobel filter was used in detecting the edges.  A sobel filter calculates the
gradient of the intensity of each pixel, giving
the direction of the largest possible increase from light to dark and also the
rate of change in that specific direction.   This results in showing how
abruptly or smoothly the images changes at that point and then how likely it
is that that part represents an edge.  The figure below shows a sobel filter
acting on a shark fin image.  The edges of the shark fin can clearly be seen.
The main purpose of these changes was to improve accuracy when detecting the
edges.  \\
\begin{figure}[H]
 \centering
 \includegraphics[width=2.5in, height=2in]{haais}
 \caption{A sobel filter applied to a shark fin image}
 \label{fin1}
\end{figure}

\newpage
\noindent Here is a comparison between the effect of the original algorithm on
one of the shark fin images and the effect of the modified version of the
algorithm on the same image.
\begin{figure}[H]
 \centering
 \includegraphics[width=4in, height=1.8in]{haaio}
 \caption{The effect of the original algorithm}
 \label{fin1}
\end{figure}

\begin{figure}[H]
 \centering
 \includegraphics[width=4in, height=1.8in]{haaim}
 \caption{The effect of the modified algorithm}
 \label{fin}
\end{figure}

\noindent It can be seen that the modified version gives better results around
the edges, which is essential in the case of the shark fin images. \\ 

Hoe kan ek hierdie deel inwerk??????

First consider reducing the running time.  One way is to look at which cell
features, i.e. difference in intensity combined with cell strength and cell
strength alone, play a more important role in updating the cell label, i.e.
foreground or background.   This will then help in finding 
redundant conditions in the code.  By eliminating those conditions the running
time can be reduced.  It is concluded that neither of the before
mentioned features can be omitted, although cell strength alone has a more
significant role in finding the new cell label.  No new 'attacking' 
strategies have yet been implemented. \\

The use of a rank filter is also being investigated.  A rank filter looks for
the cell with maximum intensity in a certain region, specified by the user, 
and assigns that intensity to the cell it is being compared to.  This will
better the way in finding the cells in a certain region with intensities that
is much different from the intensity of the cell being considered. \\  

\noindent From \cite{RF} we conclude the following.  The semantic segmentation
algorithm is based on pixel wise object segmentation.  This is done by 
assigning category labels to a set of super pixels obtained by clustering the
joint colour space and coordinate space using the mean shift algorithm.
The method of interactive semantic segmentation as in \cite{RF} can be described
as follows.  Each image is presented as a set of super pixels, where 
a super pixel is a set of pixels.  The first image in the data set must be
segmented manually by labelling each super pixel.  An appearance model is 
now created.  The next image is now segmented automatically using the appearance
model.  During the segmentation the user may correct mistakes by 
relabelling and thus updating the appearance model.  Every time the user
approves the segmentation, the system learns from the new labelling information.
As image segmentation continues, user time spent on correcting labels reduces
and thus the rate of image labelling increases.  \\

This method can be helpful in the sense that it works with a database of images
of the same kind.  Since the shark fin images are all of the same type, 
it would be very beneficial to manually segment the first image only and then
automatic segmentation will follow.  By updating the appearance model, 
one can also be certain that better segmentation results will follow.  \\  


\subsection{Random Walker}
The method, as
described in \cite{rw}, is as follows.  The user labels a few
pixels as foreground or background for example.  This is then called the seeds. 
A random walker is then released from each of the unlabelled pixels. 
Thereafter, the probability that a certain pixel's random walker first arrives
at a specific seed, is computed.\note{Look at the scikit-image gallery on
random walker to see how they explained it.  Got this from the reference they
gave there.}  In other words, if the user
labels $n$ pixels, each with a different label, then the probability that a
random walker
leaving the pixel will first arrive at a certain seed, must be
computed.  The latter is done by modelling the image as a weighted graph, where
the weight of an edge reflects the similarity(intensity values) between pixels,
and then solving a system of linear equations.  The pixel is then assigned the
label
of the seed for which it is most likely to reach.  The process is repeated until
each pixel is assigned a specific label. 


\subsection{Watershed}
\label{watershed}
Another segmentation algorithm is the classic watershed algorithm, as
implemented in \cite{scikit}.  The algorithm starts with user-defined markers,
called seed points, which can be viewed as little holes in the image, whereafter
pixel values are treated as a topography/landscape.  The algorithm then floods
basins from the user-defined markers until basins which attribute to different
markers meet at watershed lines.  In this case marker positions are chosen as
the local maxima of the image.  Thereafter the segmentation is done on the
gradient image.  The result of the watershed algorithm applied to a shark fin
image is shown below.

\begin{figure}[H]
\centering
\includegraphics[width=5in,height=2in]{watershed.png} 
\label{fig1}
\caption{The watershed algorithm}
\end{figure}

\noindent The first image shows the gradient image of the original shark fin
image.  The second image shows the pixels that are identified as a local maxima.
 The third image shows how the basins flooded until watershed lines are reached.
 Putting the correct segments together, which will require a lot of hard work,
an effective segmentation can be done.

\subsection{Graphcuts}
Graphcuts is a technique to select the best quality segmentation.  In doing so,
we calculate a global optimum solution by minimizing a certain 
cost function.  One of the reasons for the success of graphcuts is because of
the way the cost is defined.  It is a combination of what each pixel
"wants" and what is "best" for its neighbourhood.  We define an ergy function,
$E$, to determine the cost of a specific segmentation.
\[
 E = \sum_{p \in \Phi}E_d(p) + \lambda\sum_{p,g \in \Phi}E_n(p, q)
\]
where the term $E_d(p)$ is the cost of assigning pixel $p$ label $d$, the
neighbourhood term $E_n(p, q)$ is the difference in cost of labels for pixels
$p$ 
and $q$, and finally $\lambda$ is a weighting parameter to specify the
importance of either term.

\begin{figure}[H]
 \centering
 \includegraphics[width=3in]{graphcut.jpg}
 \caption{.}
\end{figure}


\newpage
\section{Results}
\subsection{}


\subsection{}


\subsection{}


\newpage
\section{Conclusions}
\subsection{Research}


\subsection{}


\subsection{Future work}
User interface.


\newpage
\bibliography{final}

\end{document}
